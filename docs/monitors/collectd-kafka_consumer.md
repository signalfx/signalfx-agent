<!--- GENERATED BY gomplate from scripts/docs/monitor-page.md.tmpl --->

# collectd/kafka_consumer

Monitors a Java based Kafka consumer using GenericJMX.

See the [integration documentation](https://github.com/signalfx/integrations/tree/master/collectd-kafka)
for more information.

This monitor has a set of [built in MBeans
configured](https://github.com/signalfx/signalfx-agent/tree/master/internal/monitors/collectd/kafkaconsumer/mbeans.go)
for which it pulls metrics from the Kafka consumer's JMX endpoint.

Sample YAML configuration:
```yaml
monitors:
  - type: collectd/kafka_consumer
    host: localhost
    port: 9099
    mBeansToOmit:
      - fetch-size-avg-per-topic
```

Note that this monitor requires Kafka v0.9.0.0 or above and collects metrics from the new consumer API.
Also, per-topic metrics that are collected by default are not available through the new consumer API in
v0.9.0.0 which can cause the logs to flood with warnings related to the MBean not being found.
Use the `mBeansToOmit` config option in such cases. The above example configuration will not attempt to
collect the MBean referenced by `fetch-size-avg-per-topic`. Here is a
[list](https://github.com/signalfx/signalfx-agent/tree/master/internal/monitors/collectd/kafkaconsumer/mbeans.go)
of metrics collected by default


Monitor Type: `collectd/kafka_consumer`

[Monitor Source Code](https://github.com/signalfx/signalfx-agent/tree/master/internal/monitors/collectd/kafkaconsumer)

**Accepts Endpoints**: **Yes**

**Multiple Instances Allowed**: Yes

## Configuration

| Config option | Required | Type | Description |
| --- | --- | --- | --- |
| `host` | **yes** | `string` | Host to connect to -- JMX must be configured for remote access and accessible from the agent |
| `port` | **yes** | `integer` | JMX connection port (NOT the RMI port) on the application.  This correponds to the `com.sun.management.jmxremote.port` Java property that should be set on the JVM when running the application. |
| `name` | no | `string` |  |
| `serviceName` | no | `string` | This is how the service type is identified in the SignalFx UI so that you can get built-in content for it.  For custom JMX integrations, it can be set to whatever you like and metrics will get the special property `sf_hostHasService` set to this value. |
| `serviceURL` | no | `string` | The JMX connection string.  This is rendered as a Go template and has access to the other values in this config. NOTE: under normal circumstances it is not advised to set this string directly - setting the host and port as specified above is preferred. (**default:** `service:jmx:rmi:///jndi/rmi://{{.Host}}:{{.Port}}/jmxrmi`) |
| `instancePrefix` | no | `string` |  |
| `username` | no | `string` |  |
| `password` | no | `string` |  |
| `customDimensions` | no | `map of strings` | Takes in key-values pairs of custom dimensions at the connection level. |
| `mBeansToCollect` | no | `list of strings` | A list of the MBeans defined in `mBeanDefinitions` to actually collect. If not provided, then all defined MBeans will be collected. |
| `mBeansToOmit` | no | `list of strings` | A list of the MBeans to omit. This will come handy in cases where only a few MBeans need to omitted from the default list |
| `mBeanDefinitions` | no | `map of objects (see below)` | Specifies how to map JMX MBean values to metrics.  If using a specific service monitor such as cassandra, kafka, or activemq, they come pre-loaded with a set of mappings, and any that you add in this option will be merged with those.  See [collectd GenericJMX](https://collectd.org/documentation/manpages/collectd-java.5.shtml#genericjmx_plugin) for more details. |


The **nested** `mBeanDefinitions` config object has the following fields:

| Config option | Required | Type | Description |
| --- | --- | --- | --- |
| `objectName` | no | `string` |  |
| `instancePrefix` | no | `string` |  |
| `instanceFrom` | no | `list of strings` |  |
| `values` | no | `list of objects (see below)` |  |
| `dimensions` | no | `list of strings` |  |


The **nested** `values` config object has the following fields:

| Config option | Required | Type | Description |
| --- | --- | --- | --- |
| `type` | no | `string` |  |
| `table` | no | `bool` |  (**default:** `false`) |
| `instancePrefix` | no | `string` |  |
| `instanceFrom` | no | `list of strings` |  |
| `attribute` | no | `string` |  |




## Metrics

The following table lists the metrics available for this monitor. Metrics that are not marked as Custom are standard metrics and are monitored by default.

| Name | Type | Custom | Description |
| ---  | ---  | ---    | ---         |
| `kafka.consumer.bytes-consumed-rate` | gauge |  | Average number of bytes consumed per second. This metric has either client-id dimension or, both client-id and topic dimensions. The former is an aggregate across all topics of the latter. |
| `kafka.consumer.fetch-rate` | gauge |  | Number of records consumed per second. |
| `kafka.consumer.fetch-size-avg` | gauge |  | Average number of bytes fetched per request. This metric has either client-id dimension or, both client-id and topic dimensions. The former is an aggregate across all topics of the latter. |
| `kafka.consumer.records-consumed-rate` | gauge |  | Average number of records consumed per second. This metric has either client-id dimension or, both client-id and topic dimensions. The former is an aggregate across all topics of the latter. |
| `kafka.consumer.records-lag-max` | gauge |  | Maximum lag in of records for any partition in this window. An increasing value over time is your best indication that the consumer group is not keeping up with the producers. |


To specify custom metrics you want to monitor, add a `metricsToInclude` filter
to the agent configuration, as shown in the code snippet below. The snippet
lists all available custom metrics. You can copy and paste the snippet into
your configuration file, then delete any custom metrics that you do not want
sent.

Note that some of the custom metrics require you to set a flag as well as add
them to the list. Check the monitor configuration file to see if a flag is
required for gathering additional metrics.

```yaml

metricsToInclude:
  - metricNames:
    monitorType: collectd/kafka_consumer
```




