package config

import (
	"net/url"
	"time"

	"github.com/mitchellh/hashstructure"
	"github.com/signalfx/signalfx-agent/internal/core/dpfilters"
	"github.com/signalfx/signalfx-agent/internal/core/propfilters"
	log "github.com/sirupsen/logrus"
)

// WriterConfig holds configuration for the datapoint writer.
type WriterConfig struct {
	// The maximum number of datapoints to include in a batch before sending the
	// batch to the ingest server.  Smaller batch sizes than this will be sent
	// if datapoints originate in smaller chunks.
	DatapointMaxBatchSize int `yaml:"datapointMaxBatchSize" default:"1000"`
	// The analogue of `datapointMaxBatchSize` for trace spans.
	TraceSpanMaxBatchSize int `yaml:"traceSpanMaxBatchSize" default:"1000"`
	// Deprecated: use `maxRequests` instead.
	DatapointMaxRequests int `yaml:"datapointMaxRequests"`
	// The maximum number of concurrent requests to make to a single ingest server
	// with datapoints/events/trace spans.  This number multipled by
	// `datapointMaxBatchSize` is more or less the maximum number of datapoints
	// that can be "in-flight" at any given time.  Same thing for the
	// `traceSpanMaxBatchSize` option and trace spans.
	MaxRequests int `yaml:"maxRequests" default:"100"`
	// The agent does not send events immediately upon a monitor generating
	// them, but buffers them and sends them in batches.  The lower this
	// number, the less delay for events to appear in SignalFx.
	EventSendIntervalSeconds int `yaml:"eventSendIntervalSeconds" default:"1"`
	// The analogue of `maxRequests` for dimension property requests.
	PropertiesMaxRequests uint `yaml:"propertiesMaxRequests" default:"100"`
	// Properties that are synced to SignalFx are cached to prevent duplicate
	// requests from being sent, causing unnecessary load on our backend.
	PropertiesHistorySize uint `yaml:"propertiesHistorySize" default:"10000"`
	// If the log level is set to `debug` and this is true, all datapoints
	// generated by the agent will be logged.
	LogDatapoints bool `yaml:"logDatapoints"`
	// The analogue of `logDatapoints` for events.
	LogEvents bool `yaml:"logEvents"`
	// The analogue of `logDatapoints` for trace spans.
	LogTraceSpans bool `yaml:"logTraceSpans"`
	// If true, and the log level is `debug`, filtered out datapoints will be
	// logged.
	LogDroppedDatapoints bool `yaml:"logDroppedDatapoints"`
	// Whether to send host correlation metrics to correlation traced services
	// with the underlying host
	SendTraceHostCorrelationMetrics *bool `yaml:"sendTraceHostCorrelationMetrics" default:"false"`
	// How long to wait after a trace span's service name is last seen to
	// continue sending the correlation datapoints for that service.  This
	// should be a duration string that is accepted by
	// https://golang.org/pkg/time/#ParseDuration.  This option is irrelvant if
	// `sendTraceHostCorrelationMetrics` is false.
	StaleServiceTimeout time.Duration `yaml:"staleServiceTimeout" default:"5m"`
	// How frequently to send host correlation metrics that are generated from
	// the service name seen in trace spans sent through or by the agent.  This
	// should be a duration string that is accepted by
	// https://golang.org/pkg/time/#ParseDuration.  This option is irrelvant if
	// `sendTraceHostCorrelationMetrics` is false.
	TraceHostCorrelationMetricsInterval time.Duration `yaml:"traceHostCorrelationMetricsInterval" default:"1m"`
	// How many trace spans are allowed to be in the process of sending.  While
	// this number is exceeded, existing pending spans will be randomly dropped
	// if possible to accommodate new spans generated to avoid memory
	// exhaustion.  If you see log messages about "Aborting pending trace
	// requests..." or "Dropping new trace spans..." it means that the
	// downstream target for traces is not able to accept them fast enough.
	// Usually if the downstream is offline you will get connection refused
	// errors and most likely spans will not build up in the agent (there is no
	// retry mechanism). In the case of slow downstreams, you might be able to
	// increase `maxRequests` to increase the concurrent stream of spans
	// downstream (if the target can make efficient use of additional
	// connections) or, less likely, increase `traceSpanMaxBatchSize` if your
	// batches are maxing out (turn on debug logging to see the batch sizes
	// being sent) and being split up too much. If neither of those options
	// helps, your downstream is likely too slow to handle the volume of trace
	// spans and should be upgraded to more powerful hardware/networking.
	MaxTraceSpansInFlight uint `yaml:"maxTraceSpansInFlight" default:"100000"`
	// The following are propagated from elsewhere
	HostIDDims          map[string]string      `yaml:"-"`
	IngestURL           string                 `yaml:"-"`
	APIURL              string                 `yaml:"-"`
	TraceEndpointURL    string                 `yaml:"-"`
	SignalFxAccessToken string                 `yaml:"-"`
	GlobalDimensions    map[string]string      `yaml:"-"`
	MetricsToInclude    []MetricFilter         `yaml:"-"`
	MetricsToExclude    []MetricFilter         `yaml:"-"`
	PropertiesToExclude []PropertyFilterConfig `yaml:"-"`
}

func (wc *WriterConfig) initialize() {
	if wc.DatapointMaxRequests != 0 {
		wc.MaxRequests = wc.DatapointMaxRequests
	} else {
		wc.DatapointMaxRequests = wc.MaxRequests
	}
}

// ParsedIngestURL parses and returns the ingest URL
func (wc *WriterConfig) ParsedIngestURL() *url.URL {
	ingestURL, err := url.Parse(wc.IngestURL)
	if err != nil {
		panic("IngestURL was supposed to be validated already")
	}
	return ingestURL
}

// ParsedAPIURL parses and returns the API server URL
func (wc *WriterConfig) ParsedAPIURL() *url.URL {
	apiURL, err := url.Parse(wc.APIURL)
	if err != nil {
		panic("apiUrl was supposed to be validated already")
	}
	return apiURL
}

// ParsedTraceEndpointURL parses and returns the trace endpoint server URL
func (wc *WriterConfig) ParsedTraceEndpointURL() *url.URL {
	if wc.TraceEndpointURL != "" {
		traceEndpointURL, err := url.Parse(wc.TraceEndpointURL)
		if err != nil {
			panic("traceEndpointUrl was supposed to be validated already")
		}
		return traceEndpointURL
	}
	return nil
}

// DatapointFilters creates the filter set for datapoints
func (wc *WriterConfig) DatapointFilters() (*dpfilters.FilterSet, error) {
	return makeFilterSet(wc.MetricsToExclude, wc.MetricsToInclude)
}

// PropertyFilters creates the filter set for dimension properties
func (wc *WriterConfig) PropertyFilters() (*propfilters.FilterSet, error) {
	return makePropertyFilterSet(wc.PropertiesToExclude)
}

// Hash calculates a unique hash value for this config struct
func (wc *WriterConfig) Hash() uint64 {
	hash, err := hashstructure.Hash(wc, nil)
	if err != nil {
		log.WithError(err).Error("Could not get hash of WriterConfig struct")
		return 0
	}
	return hash
}
