<!--- GENERATED BY gomplate from scripts/docs/monitor-page.md.tmpl --->

# elasticsearch

This monitor collects stats from Elasticsearch. It collects node, cluster
and index level stats. This monitor is compatible with the current collectd
plugin found [here] (https://github.com/signalfx/collectd-elasticsearch) in
terms of metric naming.

This monitor collects cluster level and index level stats only from the current master
in an Elasticsearch cluster by default. It is possible to override this with the
`clusterHealthStatsMasterOnly` and `indexStatsMasterOnly` config options respectively.

A simple configuration that collects only default (non-custom) metrics
looks like the following:

```yaml
monitors:
- type: elasticsearch
  host: localhost
  port: 9200
```

## Enhanced (custom) metrics

The monitor collects a subset of node stats of JVM, process, HTTP,
transport, indices and thread pool stats. It is possible to enable
enhanced stats for each stat group separately.  Note that these metrics
get categorized under the _custom_ group if you are on host-based
pricing. Here's an example:

```yaml
monitors:
- type: elasticsearch
  host: localhost
  port: 9200
  enableEnhancedHTTPStats: true
  enableEnhancedJVMStats: true
  enableEnhancedProcessStats: true
  enableEnhancedThreadPoolStats: true
  enableEnhancedTransportStats: true
  enableEnhancedNodeIndicesStats:
   - indexing
   - warmer
   - get

```

The `enableEnhancedNodeIndicesStats` option takes a list of index stats groups
for which enhanced stats will be collected. A comprehensive list of all
such available groups can be found [here](https://www.elastic.co/guide/en/elasticsearch/reference/current/cluster-nodes-stats.html#node-indices-stats).

Note that the `enableEnhancedIndexStatsForIndexGroups` is similar to
`enableEnhancedNodeIndicesStats`, but for index level stats.

## Thread Pools

By default thread pool stats from the "search" and "index" thread pools are collected. To collect
stats from other thread pools specify the `threadPools` config option:

```yaml
monitors:
- type: elasticsearch
  host: localhost
  port: 9200
  threadPools:
  - bulk
  - warmer
  - listener
```

Here is a list of valid thread pools by Elasticsearch version:

| thread pool name | ES 1.x | ES 2.0 | ES 2.1+ |
|------------------|--------|--------|--------|
| merge            | &#x2713;      |        |        |
| optimize         |&#x2713;     |        |        |
| bulk             |&#x2713;     |&#x2713;     |&#x2713;     |
| flush            |&#x2713;     |&#x2713;     |&#x2713;     |
| generic          |&#x2713;     |&#x2713;     |&#x2713;     |
| get              |&#x2713;     |&#x2713;     |&#x2713;     |
| snapshot         |&#x2713;     |&#x2713;     |&#x2713;     |
| warmer           |&#x2713;     |&#x2713;     |&#x2713;     |
| refresh          |&#x2713;     |&#x2713;     |&#x2713;     |
| fetch\_shard\_started|      |&#x2713;     |&#x2713;     |
| fetch\_shard\_store|        |&#x2713;     |&#x2713;     |
| listener         |        |&#x2713;     |&#x2713;     |
| management       |        |&#x2713;     |&#x2713;     |
| percolate        |        |&#x2713;     |&#x2713;     |
| suggest          |        |&#x2713;     |&#x2713;     |
| force\_merge      |        |        |&#x2713;     |


## Collecting index statistics

By default, the configuration parameter `indexes` is empty, which means
collect stats on all indexes. To collect statistics from a subset of
indexes, set the configuration parameter `indexes` to a list of the index
names you want to collect stats for.

The call to collect index statistics can be CPU-intensive. For this reason
SignalFx recommends using the `indexStatsIntervalSeconds` configuration
parameter to decrease the reporting interval for nodes that report index
statistics.

### Primaries vs total
By default the monitor collects a subset of index stats of total aggregation
type (see docs for details). It is possible to enable index stats of primaries
aggregation type too. Total for an index stat aggregates across all shards.
Whereas, Primaries only reflect the stats from primary shards. An example
configuration to enable index stats from Primary shards too:

```yaml
monitors:
- type: elasticsearch
  host: localhost
  port: 9200
  enableIndexStatsPrimaries: true
```

## Built-in content

For more information on the built-in content we have for Elasticsearch,
[see
here](https://github.com/signalfx/integrations/tree/master/elasticsearch).


Monitor Type: `elasticsearch`

[Monitor Source Code](https://github.com/signalfx/signalfx-agent/tree/master/internal/monitors/elasticsearch)

**Accepts Endpoints**: **Yes**

**Multiple Instances Allowed**: Yes

## Configuration

**For a list of monitor options that are common to all monitors, see [Common
Configuration](../monitor-config.md#common-configuration).**


| Config option | Required | Type | Description |
| --- | --- | --- | --- |
| `host` | **yes** | `string` |  |
| `port` | **yes** | `string` |  |
| `username` | no | `string` | Username used to access Elasticsearch stats API |
| `password` | no | `string` | Password used to access Elasticsearch stats API |
| `useHTTPS` | no | `bool` | Whether to use https or not (**default:** `false`) |
| `cluster` | no | `string` | Cluster name to which the node belongs. This is an optional config that will override the cluster name fetched from a node and will be used to populate the plugin_instance dimension |
| `enableIndexStats` | no | `bool` | Enable Index stats. If set to true, by default the a subset of index stats will be collected (see docs for list of default index metrics collected). (**default:** `true`) |
| `indexes` | no | `list of strings` | Indexes to collect stats from (by default stats from all indexes are collected) |
| `indexStatsIntervalSeconds` | no | `integer` | Interval to report IndexStats on (**default:** `60`) |
| `indexSummaryOnly` | no | `bool` | Collect only aggregated index stats across all indexes (**default:** `false`) |
| `indexStatsMasterOnly` | no | `bool` | Collect index stats only from Master node (**default:** `true`) |
| `enableClusterHealth` | no | `bool` | EnableClusterHealth enables reporting on the cluster health (**default:** `true`) |
| `clusterHealthStatsMasterOnly` | no | `bool` | Whether or not non master nodes should report cluster health (**default:** `true`) |
| `enableEnhancedHTTPStats` | no | `bool` | Enable enhanced HTTP stats (**default:** `false`) |
| `enableEnhancedJVMStats` | no | `bool` | Enable enhanced JVM stats (**default:** `false`) |
| `enableEnhancedProcessStats` | no | `bool` | Enable enhanced Process stats (**default:** `false`) |
| `enableEnhancedThreadPoolStats` | no | `bool` | Enable enhanced ThreadPool stats (**default:** `false`) |
| `enableEnhancedTransportStats` | no | `bool` | Enable enhanced Transport stats (**default:** `false`) |
| `enableEnhancedNodeIndicesStats` | no | `list of strings` | Enable enhanced node level index stats groups. A list of index stats groups for which to collect enhanced stats |
| `threadPools` | no | `list of strings` | ThreadPools to report threadpool node stats on (**default:** `[search index]`) |
| `enableEnhancedClusterHealthStats` | no | `bool` | Enable Cluster level stats. These stats report only from master Elasticserach nodes (**default:** `false`) |
| `enableEnhancedIndexStatsForIndexGroups` | no | `list of strings` | Enable enhanced index level index stats groups. A list of index stats groups for which to collect enhanced stats |
| `enableIndexStatsPrimaries` | no | `bool` | To enable index stats from only primary shards. By default the index stats collected are aggregated across all shards (**default:** `false`) |
| `metadataRefreshIntervalSeconds` | no | `integer` | How often to refresh metadata about the node and cluster (**default:** `30`) |


## Metrics

The following table lists the metrics available for this monitor.
Metrics that are categorized as
[container/host](https://docs.signalfx.com/en/latest/admin-guide/usage.html#about-custom-bundled-and-high-resolution-metrics)
are marked as _Default_ in the table below.

| Name | Type | [Default](https://docs.signalfx.com/en/latest/admin-guide/usage.html#about-custom-bundled-and-high-resolution-metrics) | [Group](#groups) | Description |
| ---  | ---  | ---    | --- | ---         |
| `elasticsearch.cluster.active-primary-shards` | gauge | ✔ | cluster | Number of active primary shards |
| `elasticsearch.cluster.active-shards` | gauge | ✔ | cluster | Number of active shards |
| `elasticsearch.cluster.active-shards-percent` | gauge |  | cluster | Percentaage of shards active |
| `elasticsearch.cluster.delayed-unassigned-shards` | gauge |  | cluster | Number of delayed unassigned shards |
| `elasticsearch.cluster.in-flight-fetches` | gauge |  | cluster | Number of fetches in-flight |
| `elasticsearch.cluster.initializing-shards` | gauge |  | cluster | Number of shards being initialized |
| `elasticsearch.cluster.number-of-data_nodes` | gauge | ✔ | cluster | Number of data nodes |
| `elasticsearch.cluster.number-of-nodes` | gauge | ✔ | cluster | Number of nodes |
| `elasticsearch.cluster.pending-tasks` | gauge |  | cluster | Number of pending tasks |
| `elasticsearch.cluster.relocating-shards` | gauge | ✔ | cluster | Number of shards being relocated |
| `elasticsearch.cluster.status` | gauge |  | cluster | Cluster stats (0, 1, 2 for green, yellow and red respectively) |
| `elasticsearch.cluster.task-max-wait-time` | gauge |  | cluster | Max time a task has to wait |
| `elasticsearch.cluster.unassigned-shards` | gauge | ✔ | cluster | Number of unassigned shards |
| `elasticsearch.http.current_open` | gauge |  | node/http | Number of currently open HTTP connections |
| `elasticsearch.http.total_open` | cumulative |  | node/http | Total number of opened HTTP connections |
| `elasticsearch.indices.completion.size` | gauge |  | indices/completion | Size used by suggest completion (in bytes) |
| `elasticsearch.indices.docs.count` | gauge | ✔ | indices/docs | Number of docs |
| `elasticsearch.indices.docs.deleted` | gauge | ✔ | indices/docs | Number of docs deleted |
| `elasticsearch.indices.fielddata.evictions` | cumulative |  | indices/fielddata | Number of evictions from fielddata cache |
| `elasticsearch.indices.fielddata.memory-size` | gauge |  | indices/fielddata | Size of fielddata cache (in bytes) |
| `elasticsearch.indices.filter-cache.evictions` | cumulative |  | indices/filter-cache | Number of evicttions from filter cache |
| `elasticsearch.indices.filter-cache.memory-size` | gauge |  | indices/filter-cache | Filter cache size (in bytes) |
| `elasticsearch.indices.flush.periodic` | gauge |  | indices/flush | How long to wait before triggering a flush regardless of translog size |
| `elasticsearch.indices.flush.total` | cumulative |  | indices/flush | Number of index flushes to disk |
| `elasticsearch.indices.flush.total-time` | cumulative |  | indices/flush | Time spent flushing the index to disk |
| `elasticsearch.indices.get.current` | gauge |  | indices/get | Number of get requests running |
| `elasticsearch.indices.get.exists-time` | cumulative |  | indices/get | Time spent on get requests where the document existed |
| `elasticsearch.indices.get.exists-total` | cumulative |  | indices/get | Number of get requests where the document existed |
| `elasticsearch.indices.get.missing-time` | cumulative |  | indices/get | Time spent on get requests where the document was missing |
| `elasticsearch.indices.get.missing-total` | cumulative |  | indices/get | Number of get requests where the document was missing |
| `elasticsearch.indices.get.time` | cumulative |  | indices/get | Time spent on get requests |
| `elasticsearch.indices.get.total` | cumulative | ✔ | indices/get | Total number of get requests |
| `elasticsearch.indices.id-cache.memory-size` | gauge |  | indices/id-cache | Size of id cache (in bytes) |
| `elasticsearch.indices.indexing.delete-current` | gauge |  | indices/indexing | Number of documents currently being deleted from an index |
| `elasticsearch.indices.indexing.delete-time` | cumulative |  | indices/indexing | Time spent deleting documents from an index |
| `elasticsearch.indices.indexing.delete-total` | cumulative |  | indices/indexing | Number of documents deleted from an index |
| `elasticsearch.indices.indexing.index-current` | gauge |  | indices/indexing | Number of documents currently being indexed to an index |
| `elasticsearch.indices.indexing.index-failed` | gauge |  | indices/indexing | Number of failed indices |
| `elasticsearch.indices.indexing.index-time` | cumulative |  | indices/indexing | Time spent indexing documents to an index |
| `elasticsearch.indices.indexing.index-total` | cumulative | ✔ | indices/indexing | Total number of documents indexed to an index |
| `elasticsearch.indices.indexing.noop-update-total` | cumulative |  | indices/indexing | Number of noop updates |
| `elasticsearch.indices.indexing.throttle-time` | cumulative |  | indices/indexing | Throttle time |
| `elasticsearch.indices.merges.auto-throttle-size` | cumulative |  | indices/merges | Merging throttled due to auto-throttling (in bytes) |
| `elasticsearch.indices.merges.current` | gauge | ✔ | indices/merges | Number of currently active segment merges |
| `elasticsearch.indices.merges.current-docs` | gauge |  | indices/merges | Number of docs currently being merged |
| `elasticsearch.indices.merges.current-size` | gauge |  | indices/merges | Size of the segments currently being merged |
| `elasticsearch.indices.merges.stopped-time` | cumulative |  | indices/merges | Total time merges were stopped for |
| `elasticsearch.indices.merges.throttle-time` | cumulative |  | indices/merges | Total time merges spent waiting due to throttling |
| `elasticsearch.indices.merges.total` | cumulative | ✔ | indices/merges | Number of segment merges |
| `elasticsearch.indices.merges.total-docs` | cumulative |  | indices/merges | Number of merged docs across merged segments |
| `elasticsearch.indices.merges.total-size` | cumulative |  | indices/merges | Total size of merged segments |
| `elasticsearch.indices.merges.total-time` | cumulative |  | indices/merges | Total time spent on merging |
| `elasticsearch.indices.percolate.current` | gauge |  | indices/percolate | Number of percolator queries currently running |
| `elasticsearch.indices.percolate.queries` | cumulative |  | indices/percolate | Number of percolator queries |
| `elasticsearch.indices.percolate.time` | cumulative |  | indices/percolate | Total time spent on percolate requests |
| `elasticsearch.indices.percolate.total` | cumulative |  | indices/percolate | Total number of suggest requests |
| `elasticsearch.indices.query-cache.cache-count` | gauge |  | indices/query-cache | Number of items in query cache |
| `elasticsearch.indices.query-cache.cache-size` | gauge |  | indices/query-cache | Size of query cache (in bytes) |
| `elasticsearch.indices.query-cache.evictions` | cumulative |  | indices/query-cache | Number of query cache evictions |
| `elasticsearch.indices.query-cache.hit-count` | cumulative |  | indices/query-cache | Number of query cache hits |
| `elasticsearch.indices.query-cache.memory-size` | gauge |  | indices/query-cache | Size of query cache (in bytes) |
| `elasticsearch.indices.query-cache.miss-count` | cumulative |  | indices/request-cache | Number of query cache misses |
| `elasticsearch.indices.query-cache.total-count` | cumulative |  | indices/query-cache | Total number of items in the query cache |
| `elasticsearch.indices.recovery.current-as-source` | gauge |  | indices/recovery | Number of ongoing recoveries for which a shard serves as a source |
| `elasticsearch.indices.recovery.current-as-target` | gauge |  | indices/recovery | Number of ongoing recoveries for which a shard serves as a target |
| `elasticsearch.indices.recovery.throttle-time` | cumulative |  | indices/recovery | Total time recoveries waited due to throttling |
| `elasticsearch.indices.refresh.listeners` | gauge |  | indices/refresh | Number of listeners waiting for a refresh |
| `elasticsearch.indices.refresh.total` | cumulative |  | indices/refresh | Total number of index refreshes |
| `elasticsearch.indices.refresh.total-time` | cumulative |  | indices/refresh | Total time spent on index refreshes |
| `elasticsearch.indices.request-cache.evictions` | cumulative |  | indices/request-cache | Number of request cache evictions |
| `elasticsearch.indices.request-cache.hit-count` | cumulative |  | indices/request-cache | Number of request cache hits |
| `elasticsearch.indices.request-cache.memory-size` | gauge |  | indices/request-cache | Memory used by request cache (in bytes) |
| `elasticsearch.indices.request-cache.miss-count` | cumulative |  | indices/request-cache | Number of request cache misses |
| `elasticsearch.indices.search.fetch-current` | gauge |  | indices/search | Number of query fetches currently running |
| `elasticsearch.indices.search.fetch-time` | cumulative |  | indices/search | Total time spent on query fetches |
| `elasticsearch.indices.search.fetch-total` | cumulative |  | indices/search | Total number of query feches |
| `elasticsearch.indices.search.open-contexts` | gauge |  | indices/search | Number of open contexts |
| `elasticsearch.indices.search.query-current` | gauge |  | indices/search | Number of currently active queries |
| `elasticsearch.indices.search.query-time` | cumulative | ✔ | indices/search | Total time spent querying on the primary |
| `elasticsearch.indices.search.query-total` | cumulative | ✔ | indices/search | Total number of queries |
| `elasticsearch.indices.search.scroll-current` | gauge |  | indices/search | Currently active scroll queries count |
| `elasticsearch.indices.search.scroll-time` | cumulative |  | indices/search | Total time spent on scroll queries |
| `elasticsearch.indices.search.scroll-total` | cumulative |  | indices/search | Total number of scroll queries |
| `elasticsearch.indices.search.suggest-current` | gauge |  | indices/search | Number of suggest requests currently active |
| `elasticsearch.indices.search.suggest-time` | cumulative |  | indices/search | Total time spent on search suggest |
| `elasticsearch.indices.search.suggest-total` | cumulative |  | indices/search | Total number of suggest requests |
| `elasticsearch.indices.segments.count` | gauge | ✔ | indices/segments | Number of segments in an index shard |
| `elasticsearch.indices.segments.doc-values-memory-size` | gauge |  | indices/segments | Memory used by doc values |
| `elasticsearch.indices.segments.fixed-bit-set-memory-size` | gauge |  | indices/segments | Memory used by fixed bit set |
| `elasticsearch.indices.segments.index-writer-max-memory-size` | gauge |  | indices/segments | Maximum memory used by the index writer |
| `elasticsearch.indices.segments.index-writer-memory-size` | gauge |  | indices/segments | Memory used by the index writer |
| `elasticsearch.indices.segments.memory-size` | gauge |  | indices/segments | Memory used by index segments (in bytes) |
| `elasticsearch.indices.segments.norms-memory-size` | gauge |  | indices/segments | Memory used by norms (in bytes) |
| `elasticsearch.indices.segments.points-memory-size` | gauge |  | indices/segments | Memory used by points |
| `elasticsearch.indices.segments.stored-field-memory-size` | gauge |  | indices/segments | Memory used by stored fields (in bytes) |
| `elasticsearch.indices.segments.term-vectors-memory-size` | gauge |  | indices/segments | Memory used by term vectors (in bytes) |
| `elasticsearch.indices.segments.terms-memory-size` | gauge |  | indices/segments | Memory used by terms (in bytes) |
| `elasticsearch.indices.segments.version-map-memory-size` | gauge |  | indices/segments | Memory used by segment version map (in bytes) |
| `elasticsearch.indices.store.size` | gauge |  | indices/store | Total size (in bytes) |
| `elasticsearch.indices.store.throttle-time` | cumulative |  | indices/store | Total time requests are throttled for |
| `elasticsearch.indices.suggest.current` | gauge |  | indices/suggest | Number of currently active suggest requests |
| `elasticsearch.indices.suggest.time` | cumulative |  | indices/suggest | Total time spent in suggest requests |
| `elasticsearch.indices.suggest.total` | cumulative |  | indices/suggest | Total number of suggest requests |
| `elasticsearch.indices.translog.earliest_last_modified_age` | gauge |  | indices/translog | Earliest last modified age on transaction logs |
| `elasticsearch.indices.translog.operations` | gauge |  | indices/translog | Number of operations in the transaction log |
| `elasticsearch.indices.translog.size` | gauge |  | indices/translog | Size of the transaction log |
| `elasticsearch.indices.translog.uncommitted_operations` | gauge |  | indices/translog | Number of uncommitted operations in the transaction log |
| `elasticsearch.indices.translog.uncommitted_size_in_bytes` | gauge |  | indices/translog | Size of uncommitted transaction logs (in bytes) |
| `elasticsearch.indices.warmer.current` | gauge |  | indices/warmer | Number of currently active warmers |
| `elasticsearch.indices.warmer.total` | cumulative |  | indices/warmer | Total number of warmers |
| `elasticsearch.indices.warmer.total-time` | cumulative |  | indices/warmer | Total time spent by warmers |
| `elasticsearch.jvm.classes.current-loaded-count` | gauge |  | node/jvm | Number of classes currently loaded |
| `elasticsearch.jvm.classes.total-loaded-count` | cumulative |  | node/jvm | Number of classes loaded |
| `elasticsearch.jvm.classes.total-unloaded-count` | cumulative |  | node/jvm | Total number of classes unloaded |
| `elasticsearch.jvm.gc.count` | cumulative |  | node/jvm | Total number of garbage collections |
| `elasticsearch.jvm.gc.old-count` | cumulative |  | node/jvm | Total number of garbage collections on Old Gen |
| `elasticsearch.jvm.gc.old-time` | cumulative |  | node/jvm | Total time spent in garbage collections on Old Gen |
| `elasticsearch.jvm.gc.time` | cumulative | ✔ | node/jvm | Total time spent on GC |
| `elasticsearch.jvm.mem.buffer_pools.direct.count` | gauge |  | node/jvm | Number of direct buffer pools |
| `elasticsearch.jvm.mem.buffer_pools.direct.total_capacity_in_bytes` | gauge |  | node/jvm | Total capacity of direct buffer pools |
| `elasticsearch.jvm.mem.buffer_pools.direct.used_in_bytes` | gauge |  | node/jvm | Memory used by direct buffer pools (in bytes) |
| `elasticsearch.jvm.mem.buffer_pools.mapped.count` | gauge |  | node/jvm | Number of buffers in the mapped pool |
| `elasticsearch.jvm.mem.buffer_pools.mapped.total_capacity_in_bytes` | gauge |  | node/jvm | Total capacity of the buffers in the mapped pool |
| `elasticsearch.jvm.mem.buffer_pools.mapped.used_in_bytes` | gauge |  | node/jvm | Memory used by mapped buffer pools (in bytes) |
| `elasticsearch.jvm.mem.heap-committed` | gauge | ✔ | node/jvm | Memory guaranteed to be available to JVM heap |
| `elasticsearch.jvm.mem.heap-max` | gauge |  | node/jvm | Max memory that can be used by JVM heap (in bytes) |
| `elasticsearch.jvm.mem.heap-used` | gauge | ✔ | node/jvm | Memory current being used by JVM heap (in bytes) |
| `elasticsearch.jvm.mem.heap-used-percent` | gauge |  | node/jvm | Percent of heap being used |
| `elasticsearch.jvm.mem.non-heap-committed` | gauge |  | node/jvm | Memory guaranteed to be available to JVM non-heap |
| `elasticsearch.jvm.mem.non-heap-used` | gauge |  | node/jvm | Memory current being used by JVM non-heap (in bytes) |
| `elasticsearch.jvm.mem.pools.old.max_in_bytes` | gauge |  | node/jvm | Memory used by Old Gen (in bytes) |
| `elasticsearch.jvm.mem.pools.old.peak_max_in_bytes` | gauge |  | node/jvm | Memory pool Old Gen peak max (in bytes) |
| `elasticsearch.jvm.mem.pools.old.peak_used_in_bytes` | gauge |  | node/jvm | Peak memory used by Old Gen (in bytes) |
| `elasticsearch.jvm.mem.pools.old.used_in_bytes` | gauge |  | node/jvm | Memory being used by Old Gen (in bytes) |
| `elasticsearch.jvm.mem.pools.survivor.max_in_bytes` | gauge |  | node/jvm | Max memory that can be used by Survivor space (in bytes) |
| `elasticsearch.jvm.mem.pools.survivor.peak_max_in_bytes` | gauge |  | node/jvm | Memory used by Survivor space (in bytes) |
| `elasticsearch.jvm.mem.pools.survivor.peak_used_in_bytes` | gauge |  | node/jvm | Peak memory used by Survivor space (in bytes) |
| `elasticsearch.jvm.mem.pools.survivor.used_in_bytes` | gauge |  | node/jvm | Memory being used currently by Survivor space (in bytes) |
| `elasticsearch.jvm.mem.pools.young.max_in_bytes` | gauge |  | node/jvm | Max memory (in bytes) that can be used by Young Gen |
| `elasticsearch.jvm.mem.pools.young.peak_max_in_bytes` | gauge |  | node/jvm | Memory pool Young Gen peak max (in bytes) |
| `elasticsearch.jvm.mem.pools.young.peak_used_in_bytes` | gauge |  | node/jvm | Memory pool Young Gen peak used (in bytes) |
| `elasticsearch.jvm.mem.pools.young.used_in_bytes` | gauge |  | node/jvm | Memory used by Young Gen (in bytes) |
| `elasticsearch.jvm.threads.count` | gauge |  | node/jvm | Number of active threads in the JVM |
| `elasticsearch.jvm.threads.peak` | gauge |  | node/jvm | Peak number of threads used |
| `elasticsearch.jvm.uptime` | cumulative |  | node/jvm | Uptime of JVM |
| `elasticsearch.process.cpu.percent` | gauge |  | node/process | CPU usage in percent |
| `elasticsearch.process.cpu.time` | cumulative |  | node/process | CPU time (in milliseconds) used by the process on which the Java virtual machine is running |
| `elasticsearch.process.max_file_descriptors` | gauge |  | node/process | Number of opened file descriptors associated with the current process |
| `elasticsearch.process.mem.total-virtual-size` | cumulative |  | node/process | Size in bytes of virtual memory that is guaranteed to be available to the running process |
| `elasticsearch.process.open_file_descriptors` | gauge | ✔ | node/process | Number of currently open file descriptors |
| `elasticsearch.thread_pool.active` | gauge |  | node/thread-pool | Number of active threads |
| `elasticsearch.thread_pool.completed` | cumulative |  | node/thread-pool | Number of threads completed in thread pool |
| `elasticsearch.thread_pool.largest` | gauge |  | node/thread-pool | Highest active threads in thread pool |
| `elasticsearch.thread_pool.queue` | gauge |  | node/thread-pool | Number of Tasks in thread pool |
| `elasticsearch.thread_pool.rejected` | cumulative | ✔ | node/thread-pool | Number of rejected threads in thread pool |
| `elasticsearch.thread_pool.threads` | cumulative |  | node/thread-pool | Number of Threads in thread pool |
| `elasticsearch.transport.rx.count` | cumulative |  | node/transport | Total size of data received in cluster communication (in bytes) |
| `elasticsearch.transport.rx.size` | cumulative |  | node/transport | Total size of data received in cluster communication |
| `elasticsearch.transport.server_open` | gauge |  | node/transport | Total number of connections opened for cluster communication |
| `elasticsearch.transport.tx.count` | cumulative |  | node/transport | Total number of packets sent in cluster communication |
| `elasticsearch.transport.tx.size` | cumulative |  | node/transport | Total size of data sent in cluster communication |



### Non-default metrics (version 4.7.0+)

**The following information applies to the agent version 4.7.0+ that has
`enableBuiltInFiltering: true` set on the top level of the agent config.**

To emit metrics that are not _default_, you can add those metrics in the
generic monitor-level `extraMetrics` config option.  Metrics that are derived
from specific configuration options that do not appear in the above table do
not need to be added to `extraMetrics`.

To see a list of metrics that will be emitted you can run `agent-status
monitors` after configuring this monitor in a running agent instance.


#### Groups
You can enable an entire group of metrics by specifying the `extraGroups` config
option in your monitor config.  The value is a list of group names to enable.

### Legacy non-default metrics (version < 4.7.0)

**The following information only applies to agent version older than 4.7.0. If
you have a newer agent and have set `enableBuiltInFiltering: true` at the top
level of your agent config, see the section above. See upgrade instructions in
[Old-style whitelist filtering](../legacy-filtering.md#old-style-whitelist-filtering).**

If you have a reference to the `whitelist.json` in your agent's top-level
`metricsToExclude` config option, and you want to emit metrics that are not in
that whitelist, then you need to add an item to the top-level
`metricsToInclude` config option to override that whitelist (see [Inclusion
filtering](../legacy-filtering.md#inclusion-filtering).  Or you can just
copy the whitelist.json, modify it, and reference that in `metricsToExclude`.

## Dimensions

The following dimensions may occur on metrics emitted by this monitor.  Some
dimensions may be specific to certain metrics.

| Name | Description |
| ---  | ---         |
| `aggregation` | Aggregation of index metrics. Whether the value of the metric is from the primary shard only or across all shards. Valid values - primaries, total respectively (only on index stats) |
| `cluster` | Name of Elasticsearch the cluster. |
| `index` | Name of index (only on per index mertics) |
| `node_id` | ID of a Elasticsearch node (only on node mertics) |
| `node_name` | Human readable name of a node (only on node mertics) |
| `plugin_instance` | Name of the Elasticsearch cluster. For compatibility with collectd/elasticsearch built-in content |
| `thread_pool` | Name of thread pool (only on thread pool mertics) |



